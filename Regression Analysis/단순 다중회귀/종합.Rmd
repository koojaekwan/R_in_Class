---
title: "Mid-Exam data"
author: "Jae Kwan Koo"
output:
  html_document:
    df_print: paged
    code_folding: show
    fig_height: 6
    fig_width: 10
    highlight: textmate
    toc: yes
    toc_depth: 4
    toc_float: yes
    theme : united
  github_document:
    toc: yes
    toc_depth: 4
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, fig.align = "center", message=F, warning=F, cache=F, dpi = 300, dev = "png")
```  


```{r echo=FALSE}
setwd("D:\\Jae Kwan\\4학년1학기\\선형모형응용 이상진\\7주차-중간고사")
```  


## Library  

```{r message=FALSE, warning=FALSE}
# manupulate
library(data.table)
library(tidyverse)

# data visualization
library(corrplot)
library(ggridges)
library(GGally)
library(ggthemes)
library(DT)

library(lmtest)  # durbin-watson test
library(lm.beta) # standardized coefficeint
library(olsrr) # Cp
library(qpcR)  # PRESSp
library(car) # vif
```  

## Data - MID_EXAM  

```{r}
data <- fread("MID_EXAM.csv", data.table = F)
```  

## EDA {.tabset .tabset-fade .tabset-pills}  

### Data  

```{r}
datatable(data)
```  

### 데이터 요약  

```{r}
str(data)
summary(data)
```  

### 종속변수의 정규성 검정  

```{r}
shapiro.test(data$y)
MVN::mvn(data) 
```  

다변량 정규성과 y의 shapiro wilks의 정규성검정을 둘 다 진행 해보았다.  
다변량 정규성을 만족하고 y변수의 정규성도 만족한다.  


### Boxplot  

```{r}
data %>% gather(key="Var",value="value") %>% 
  ggplot(aes(x=Var, y=value, fill=Var)) +
  geom_boxplot()
```  

x4는 여기서 dummy variable이다.(1과 0을 가진다.)  

### Density  

```{r}
data %>% gather(key="Var",value="value") %>% 
  ggplot(aes(x=value, y=Var)) + 
  geom_density_ridges()


data %>% gather(key="Var",value="value") %>% 
  ggplot(aes(x=value, fill=Var))  + 
  geom_density(alpha=0.30) +
  theme_pander()
```  

### Corrplot  


```{r}
data %>% 
  select_if(is.numeric) %>%
  cor(use="complete.obs") %>%
  corrplot(method = "number", type = "upper", tl.srt = 45, tl.cex = 0.7)


ggpairs(data) 
```  

x4는 가변수를 나타낸다.  
종속변수 y는 x1과 x2와 특히 상관관계가 커보이고, x1,x2사이에도 큰 관계가 있다.  
x1과 x2사이에 다중공선성이 의심되는 상황이다. 다중공선성이 있는지 잠시 후 알아보자.  

##

content below tabbed region  



## Modeling  

```{r}
options("scipen" = 100)  # 지수표현 숫자로 표시


model <- lm(y~x1+x2+x3+factor(x4), data = data)

Anova_table <- function(model_name){
  library(lm.beta)
  library(dplyr)
  
  a<-summary(model_name)
  b<-lm.beta(model_name)
  
  a2 <- data.frame(a$coefficients)
  b2 <- b$standardized.coefficients %>% data.frame
  names(b2) <- "standardized coefficient"
  names(a2) <- c("coefficient", "standard error","t","p")
  
  model_table <- cbind(a2,b2)[,c(1,5,2,3,4)] %>% round(3)
  

  result <- model_table %>% 
    mutate(" " = case_when(
      cbind(a2,b2)[,c(1,5,2,3,4)]$p >=0.05 & cbind(a2,b2)[,c(1,5,2,3,4)]$p <0.1 ~ ".",
      cbind(a2,b2)[,c(1,5,2,3,4)]$p >=0.01 & cbind(a2,b2)[,c(1,5,2,3,4)]$p <0.05 ~ "*",
      cbind(a2,b2)[,c(1,5,2,3,4)]$p >=0.001 & cbind(a2,b2)[,c(1,5,2,3,4)]$p <0.01 ~ "**",
      cbind(a2,b2)[,c(1,5,2,3,4)]$p >=0 & cbind(a2,b2)[,c(1,5,2,3,4)]$p <0.001 ~ "***",
      T ~ ""))
  
  rownames(result) <- c("Intercept", "x1", "x2", "x3", "x4")
  
  return(result)
}


Anova_table(model)
```  

적합된 회귀식은 $\hat{y} = -0.164X_0+0.295X_1+0.179X_2-0.398X_3+0.114X_4$ 이다.  
이 계수로는 어느 변수가 영향을 크게 미치는지 알 수 없으므로 표준화 회귀계수를 살펴보자.  
표준화 회귀계수 단위를 배제시켜 회귀계수의 상대적 중요성을 알 수 있다.  
x1 x2 x3 x4순으로 모형에 영향을 미치는 정도가 다름을 알 수 있다.  

여기서 유의한 변수는 x1과 x2이다.  
하지만 아래에서 나오겠지만, x1과 x2변수 사이에는 다중공선성이 존재한다.  



<br>

```{r}
f_adjr_p <- function(model_name){
  library(dplyr)
  
  adj_r <- summary(model_name)$adj.r.squared
  
  f <- summary(model_name)$fstatistic
  p <- pf(f[1],f[2],f[3], lower.tail=F)
  attributes(p) <- NULL
  
  value <- data.frame(F = f[1], p_value = p, Adj_r_squared = adj_r) %>% round(3)
  return(value)
}



f_adjr_p(model)
```  

F-statistics가 충분히 크고 p-value는 소수점 3자리에서 0.000이다. 따라서 모든 회귀계수가 0이라는 가설을 기각할 수 있다. 즉, 모형은 적절하다고 여겨진다.  

정확한 모형의 p-value는 F통계량을 이용하여 구할 수 있다. 정확한 값은 $4.817438\times10^{-17}$이다.  

adjusted r squared는 0.953이다. 결정계수 값은 회귀계수가 늘어날수록 증가하는 추세를 보인다.  따라서 다중회귀에서 수정된 결정계수 값을 보는 것이 더 타당하다. 늘어난 회귀계수가 모형에 영향이 미미할지라도 결정계수는 늘어날 것이기 때문에 이를 보완하여 수정된 결정계수를 고려한다.  

```{r}
pf(summary(model)$fstatistic[1], summary(model)$fstatistic[2], summary(model)$fstatistic[3], lower.tail=F)
```


$$
adj R^2 = 1-{SSE/(n-p)\over SST/(n-1)}
$$  



<br>  





### VIF  

```{r}
car::vif(model)
```  

vif값이 10이 넘는 변수는 x1과 x2이다. 이 두 변수 사이에 다중공선성이 확실히 존재하는 것 같다.  
x2변수를 제거하는 것을 고려해보자.  


```{r}
model_new <- lm(y~x1+x3+x4, data = data)

car::vif(model_new)
```  

vif값을 보니 이제 안정적이다.  
이 모형을 이제 full_model로 취급하겠다.  


```{r}
summary(model_new)
```  

### 잔차도표  

```{r}
par(mfrow=c(2,2))

plot(model_new)
```  

등분산을 만족하는 것처럼 보인다.  
영향력 관측치로 보이는 점이 소수있지만, 큰 문제로 보이지는 않는다.  
`influence.measures(model_new)`함수로 보면 20, 22번 관측치가 영향력 관측치라고 표시되고 있다.   



### Durbin watson  

```{r}
dwtest(model_new)
```  

D값이 2 근처이면 자기상관이 0에 가깝다.  
D값이 0 근처이면 양의 자기상관을 갖는다.  

$H_0 : \rho =0$  

p-value가 유의수준 0.05보다 크므로 자기상관성이 없다고 볼 수 있다.  






### Variance Selection {.tabset .tabset-fade .tabset-pills}  

#### Null model  

```{r}
model_intercept <- lm(y~1, data = data)

summary(model_intercept)
```  


#### Forward  

```{r}
model_forward <- step(model_intercept, scope = ~x1+x3+factor(x4),
                      data = data, direction = "forward", trace = F)

summary(model_forward)
```  

#### Backward  

```{r}
model_backward <- step(model_new, data = data, direction = "backward", trace = F)

summary(model_backward)
```  

#### Stepwise  

```{r}
model_stepwise <- step(model_intercept, scope = ~x1+x3+factor(x4),
                      data = data, direction = "both", trace = F)

summary(model_stepwise)
```  

### Comparison {.tabset .tabset-fade .tabset-pills}  

#### AIC  

```{r eval=FALSE}
AIC(model_new)

AIC(model_intercept)

AIC(model_forward)
AIC(model_backward)
AIC(model_stepwise)
```  

|모형|AIC|
|:------:|:------:|
|full model|`r AIC(model_new) %>% round(3)`|
|null model|`r AIC(model_intercept) %>% round(3)`|
|forward model|`r AIC(model_forward) %>% round(3)`|
|backward model|`r AIC(model_backward) %>% round(3)`|
|stepwise model|`r AIC(model_stepwise) %>% round(3)`|  


* 통계학의 많은 분야에서 사용되는 모형 선택 기준  
* 가능도함수의 크기와 모수의 개수를 함께 반영  
* AIC값이 작을수록 좋은 모형으로 판정  
* 모형이 복잡할수록(모수가 많을수록, p가 클수록) 벌칙  

* SBS,  BIC등 응용된 Criterion 정의  


AIC = $-2logL(\hat\theta)+2p$  

<br>
<br>


#### PRESSp  

```{r eval=FALSE}
PRESS(model_new)$stat

PRESS(model_intercept)$stat

PRESS(model_forward)$stat
PRESS(model_backward)$stat
PRESS(model_stepwise)$stat
```  

|모형|PRESSp|
|:------:|:------:|
|full model|`r PRESS(model_new)$stat %>% round(3)`|
|null model|`r PRESS(model_intercept)$stat %>% round(3)`|
|forward model|`r PRESS(model_forward)$stat %>% round(3)`|
|backward model|`r PRESS(model_backward)$stat %>% round(3)`|
|stepwise model|`r PRESS(model_stepwise)$stat %>% round(3)`|  

모형선택의 기준인 $R_p^2$, $s_p^2$, $C_p$등은 관측된 자료들에 대한 현재모형의 적합도(quality of fit)가 얼마나 좋은 지를 나타내는 측도들이다.  
그러나 회귀분석에서 중요한 목적 중의 하나는 예측인데, 실제 문제들에 있어서 적합도가 높은 모형이더라도 낮은 예측도(quality of prediction)를 갖는 경우가 있다. 그러므로 정확도가 높은 예측이 중요한 분석 목적인 경우에는 적합도보다 예측도가 높은 모형을 선택할 필요가 있다.  

PRESSp는 예측도를 나타내는 측도이다.  
예측오차제곱합(prediction error sum of squares)을 나타낸다.  

$$
PRESS_p = \sum_{i=1}^n (y_i-\hat{y}_{i(i)})^2
$$  

n개의 자료를 나누어서 (n-1)개는 추정에 이용하고 나머지 한 개는 예측의 정확도 계산에 사용한 것이다. 이는 cross validation의 개념과 같다.  

**이 PRESSp의 값을 최소화하는 모형을 최적모형으로 선택하면 된다.**  

<br>
<br>


#### Mallow's Cp  

```{r eval=FALSE}
ols_mallows_cp(model_new, model_new) # equivalent to p

ols_mallows_cp(model_intercept, model_new)

ols_mallows_cp(model_forward, model_new)
ols_mallows_cp(model_backward, model_new)
ols_mallows_cp(model_stepwise, model_new)
```  

|모형|Cp|
|:------:|:------:|
|full model|`r ols_mallows_cp(model_new, model_new) %>% round(3)`|
|null model|`r ols_mallows_cp(model_intercept, model_new) %>% round(3)`|
|forward model|`r ols_mallows_cp(model_forward, model_new) %>% round(3)`|
|backward model|`r ols_mallows_cp(model_backward, model_new) %>% round(3)`|
|stepwise model|`r ols_mallows_cp(model_stepwise, model_new) %>% round(3)`|  

적합치의 총 평균 오차제곱(total mean squared error)을 최소화 하기 위한 것이다.  
**Cp를 변수선택의 기준으로 사용할 때는 Cp를 최소화하는 모형을 최적모형으로 한다.**  



* 적합값의 총 평균제곱오차를 최소화하기 위한 기준  
* Cp=p 에 가까운 모형을 최적 모형으로 선택  

Cp통계량은 낮은 검정오차를 갖는 모델에 대해 작은 값을 가지는 경향이 있으므로. 모델들의 집합에서 최고 모델을 결정할 때 가장 낮은 Cp값을 가지는 모델을 선택한다.  

full model의 Cp는 p와 같다. 여기서는 x2를 제외시켰기 때문에 p=4이다.  


##

content below tabbed region  


## Summary  

forward, backward, stepwise방법 모두 같은 결과를 보여주며 full model보다 더 적절한 모형이라고 할 수 있다.  

```{r}
plot(NULL, type="n", xlab="", ylab="", xlim=c(-30, 55), ylim=c(-15, 30),
     main = "Full model VS Stepwise model")

abline(model_new, col="red")
abline(model_stepwise, col ="blue")

text(-5,15,"lm(y~x1+x3+factor(x4)) : full model" , col = "red")
text(20,-5,"lm(y~x1+x2) : stepwise model", col = "blue")
```



























